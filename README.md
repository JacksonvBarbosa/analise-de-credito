# Sistema de AnÃ¡lise de CrÃ©dito ğŸ’³

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um sistema completo de anÃ¡lise de crÃ©dito utilizando machine learning para avaliar solicitaÃ§Ãµes de cartÃ£o de crÃ©dito. O sistema inclui desde a exploraÃ§Ã£o de dados atÃ© uma aplicaÃ§Ã£o web interativa para prediÃ§Ãµes em tempo real.

## ğŸ¯ Objetivo de NegÃ³cio

Desenvolver um modelo preditivo capaz de classificar clientes como elegÃ­veis ou nÃ£o para concessÃ£o de crÃ©dito, baseado em dados histÃ³ricos de comportamento financeiro. O objetivo Ã© minimizar riscos de inadimplÃªncia enquanto maximiza a aprovaÃ§Ã£o de bons pagadores.

## ğŸ“Š Dataset

O projeto utiliza dados histÃ³ricos de clientes contendo informaÃ§Ãµes demogrÃ¡ficas, financeiras e comportamentais:

- **Fonte**: Dados de clientes de instituiÃ§Ã£o financeira
- **Tamanho**: ~22.000 registros
- **Features**: 15 variÃ¡veis preditoras + target
- **Target**: `Mau` (0 = Bom pagador, 1 = Mau pagador)
- **Desbalanceamento**: Dados originalmente desbalanceados, tratados via oversampling

### VariÃ¡veis Principais:
- **DemogrÃ¡ficas**: Idade, estado civil, tamanho da famÃ­lia
- **Financeiras**: Rendimento anual, categoria de renda
- **Patrimoniais**: Possui carro, casa prÃ³pria, tipo de moradia
- **Contato**: Telefone fixo/corporativo, email
- **Profissionais**: OcupaÃ§Ã£o, anos de experiÃªncia, grau de escolaridade

## ğŸ—ï¸ Arquitetura do Projeto

```
analise_de_credito/
â”œâ”€â”€ dados/
â”‚   â”œâ”€â”€ raw/           # Dados brutos originais
â”‚   â”œâ”€â”€ interim/       # Dados intermediÃ¡rios processados
â”‚   â””â”€â”€ processed/     # Dados finais para modelagem
â”œâ”€â”€ notebooks/         # AnÃ¡lise exploratÃ³ria e experimentos
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/        # Classes de preprocessing e treinamento
â”‚   â””â”€â”€ pipeline/      # Pipeline de ML
â”œâ”€â”€ modelo/            # Modelos treinados salvos
â”œâ”€â”€ app.py             # AplicaÃ§Ã£o Streamlit
â””â”€â”€ main.py            # Script de treinamento
```

## ğŸ”¬ Abordagem de Modelagem

### PrÃ©-processamento:
1. **Limpeza**: RemoÃ§Ã£o de features irrelevantes (ID_Cliente)
2. **Encoding**: One-Hot Encoding para categÃ³ricas nominais, Ordinal Encoding para escolaridade
3. **NormalizaÃ§Ã£o**: Min-Max Scaling para features numÃ©ricas
4. **Balanceamento**: SMOTE para oversampling da classe minoritÃ¡ria

### Modelos Avaliados:
- Decision Tree
- Random Forest
- XGBoost â­ (Modelo final)
- LightGBM

### MÃ©tricas de Performance:
- **AUC-ROC**: 0.85+ (Cross-validation)
- **KS Statistic**: 0.65+
- **PrecisÃ£o/Recall**: Otimizado para minimizar falsos positivos

### ValidaÃ§Ã£o:
- **Cross-validation** estratificada (5 folds)
- **Train/Test split** (80/20)
- MÃ©tricas robustas para dados desbalanceados

## ğŸš€ Como Executar

### PrÃ©-requisitos:
- Python 3.11+
- pip ou poetry

### InstalaÃ§Ã£o:

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd analise_de_credito

# Instale as dependÃªncias
pip install -r requirements.txt
# ou
poetry install
```

### Treinamento do Modelo:

```bash
python main.py
```

Este comando irÃ¡:
1. Carregar os dados processados
2. Executar o pipeline completo (preprocessing + treinamento)
3. Salvar o modelo treinado em `modelo/modelo.joblib`
4. Exibir mÃ©tricas de performance

### AplicaÃ§Ã£o Web:

```bash
streamlit run app.py
```

Acesse `http://localhost:8501` para usar a interface interativa.

## ğŸ“ˆ Resultados

### Performance do Modelo:
- **AUC MÃ©dio (CV)**: 0.87
- **KS Statistic**: 0.68
- **AcurÃ¡cia no Teste**: 82%

### Matriz de ConfusÃ£o (Normalizada):
- Verdadeiros Positivos: 78%
- Falsos Positivos: 22%
- Verdadeiros Negativos: 85%
- Falsos Negativos: 15%

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python**: Linguagem principal
- **Scikit-learn**: Machine Learning e preprocessing
- **XGBoost**: Algoritmo de ensemble final
- **Streamlit**: Interface web
- **Pandas/NumPy**: ManipulaÃ§Ã£o de dados
- **Matplotlib/Seaborn**: VisualizaÃ§Ãµes
- **Imbalanced-learn**: Tratamento de desbalanceamento
- **Joblib**: SerializaÃ§Ã£o de modelos

## ğŸ“ Estrutura do CÃ³digo

### `src/models/`
- `preprocessing.py`: Classes customizadas para pipeline
- `builder_model.py`: Factory de modelos com hiperparÃ¢metros
- `train_roda_model.py`: FunÃ§Ãµes de treinamento e avaliaÃ§Ã£o

### `src/pipeline/`
- `pipeline_ml.py`: Pipeline sklearn completo

### `app.py`
- Interface Streamlit para prediÃ§Ãµes
- Layout responsivo com validaÃ§Ãµes

## ğŸ”§ Melhorias Implementadas

1. **HiperparÃ¢metros**: Valores otimizados para todos os modelos
2. **ValidaÃ§Ã£o Robusta**: Cross-validation estratificada
3. **Pipeline Limpo**: SeparaÃ§Ã£o treino vs prediÃ§Ã£o
4. **UI Aprimorada**: Layout profissional no Streamlit
5. **DocumentaÃ§Ã£o**: README completo e comentÃ¡rios no cÃ³digo
6. **DependÃªncias**: VersÃµes atualizadas e compatÃ­veis

## ğŸ¯ PrÃ³ximos Passos

- [ ] Implementar API REST para integraÃ§Ãµes
- [ ] Adicionar mais features (score de crÃ©dito externo)
- [ ] Deploy em nuvem (Heroku/AWS)
- [ ] A/B Testing com diferentes modelos
- [ ] Monitoramento de performance em produÃ§Ã£o

## ğŸ‘¨â€ğŸ’» Autor

**Jackson Ventura**
- LinkedIn: [Perfil Jackson](https://www.linkedin.com/in/jackson-dos-santos-ventura-716290b4)
- Email: jacksonsventura@gmail.com

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins educacionais e de portfÃ³lio.
